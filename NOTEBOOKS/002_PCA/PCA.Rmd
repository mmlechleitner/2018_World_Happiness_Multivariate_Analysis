---
title: "PCA"
output: html_document
---

PCA Analysis based on the transformed df "full_best_df.csv"

```{r, echo = TRUE, fig.width=8, fig.height=8}
#------------------------------------------LOADING---------------------------------------------
require(dplyr)
require(FactoMineR)
require(factoextra)
require(corrplot)

full_best_df <- read.csv("C:/Users/A541U/Desktop/Semester 2/Descriptive R Project/2018_World_Happiness_Multivariate_Analysis/DATA/full_best_df.csv")

temp_df <- full_best_df %>% 
  select(-X,-Country,-Region,-Happiness_Score,
         -Total_Population,-Mental_and_Substance_Disorder_Index,-Compulsory_Education_in_Years,-Agricultural_Land_Percentage,-Generosity,-Forest_Area_Land_Percentage,-Suicide_Index,-Legal_Rights_Index)
```

PCA Function, 2 corr. plots of individuals and variables and a scree plot:
```{r, echo = TRUE, fig.width=8, fig.height=8}
res.pca <- PCA(temp_df,graph=T) #Biplot of PC1 and PC2
print(res.pca)
fviz_eig(res.pca, addlabels=TRUE) #Use of factoextra package for visualization instead of factominer
```

Extract the results for variables and individuals, respectively:
```{r, echo = TRUE, fig.width=8, fig.height=8}
var <- get_pca_var(res.pca) #variables
ind <- get_pca_ind(res.pca) #individuals

row.names(res.pca$ind$coord) <- full_best_df$Country #replace number of each row by country name.

res.pca$ind$coord #same as dimdesc but layout ease the comparison between PCs
res.pca$var$coord # Contribution of each country to each PCs

#var/ind$coord -> coordinates
#var/ind$cos2 -> quality of the factored map
#var/ind$contrib -> contributions to the PCs
```

Tables to see the contribution of each variable to the 3 or 5 first PCs:
```{r, echo = TRUE, fig.width=8, fig.height=8}
dimdesc(res.pca) #Easy way to see the contribution of each component's variables
```

Quality of representation (cos2) of each variable and country on the 5 first PCs:
Note: High cos2 indicates a good representation, a low one shows the opposite. 
```{r, echo = TRUE, fig.width=8, fig.height=8}
#VARIABLES:
corrplot(var$cos2, is.corr=F)

# Color by cos2 values: quality on the factor map
fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE) # Avoid text overlapping

#COUNTRIES:
row.names(res.pca$ind$cos2) <- full_best_df$Country #replace number of each row by country name.
corrplot(res.pca$ind$cos2[1:45,], is.corr=F)
corrplot(res.pca$ind$cos2[46:91,], is.corr=F)
corrplot(res.pca$ind$cos2[91:132,], is.corr=F)

fviz_pca_ind(res.pca, col.ind = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE) # Avoid text overlapping (slow if many points)

fviz_cos2(res.pca, choice = "ind", top=30) #Quality of representation graph
```

The contributions of variables in accounting for the variability in a given principal component are expressed in percentage.
Now let see the contribution of each variable to the first 5 PCs. (the larger the value, the better)
```{r, echo = TRUE, fig.width=8, fig.height=8}
# Total Contributions of variables to PC1 and PC2
fviz_contrib(res.pca, choice = "var", axes = 1:2, top = 20) #20 variables 

fviz_contrib(res.pca, choice = "ind", axes = 1:2, top=40) #TOP 40 Countries (more is not readable)
```

Classification of variables and countries (separetely) into X groups using the kmeans clustering algorithm:
```{r, echo = TRUE, fig.width=8, fig.height=8}

# Create a grouping variable using kmeans
# Create 3 groups of variables (centers = 3)
set.seed(123)
res.km <- kmeans(var$coord, centers = 3, nstart = 25)
grp <- as.factor(res.km$cluster)
# Color variables by groups
fviz_pca_var(res.pca, col.var = grp, 
             palette = c("#0073C2FF", "#EFC000FF", "#868686FF"),
             legend.title = "Cluster", repel=TRUE)


# Create a grouping of countries using kmeans
# Create 3 groups of countries (centers = 3)
set.seed(123)
res.km <- kmeans(ind$coord, centers = 3, nstart = 25)
grp <- as.factor(res.km$cluster)
# Color countries by groups
fviz_pca_ind(res.pca, col.ind = grp, 
             palette = c("#0073C2FF", "#EFC000FF", "#868686FF"),
             legend.title = "Cluster",repel=TRUE)
```

Visuals of the contribution of countries to the two first PCs:
```{r, echo = TRUE, fig.width=8, fig.height=8}

target_Factorised <- full_best_df

target_Factorised$Happiness_Score <- cut(target_Factorised$Happiness_Score,breaks=3)
fviz_pca_ind(res.pca,
             geom.ind = "text", # show points only (nbut not "text")
             col.ind = target_Factorised$Happiness_Score, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups")

###REGION CLUSTER GROUPS ON PCA
fviz_pca_ind(res.pca,
             geom.ind = "point", # show points only (nbut not "text")
             col.ind = full_best_df$Region, # color by groups
             palette = c("blue","red","yellow","black","brown",
                         "purple","green","orange","darkgray","darkgoldenrod4"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups")


# bad bad visual
fviz_pca_biplot(res.pca, repel = TRUE,
                col.var = "#2E9FDF", # Variables color
                col.ind = "#696969")  # Individuals color
```


3D Plot visualisation test (not good):
```{r, echo = TRUE, fig.width=8, fig.height=8}
require(plot3D)

a <- res.pca$ind$coord[,1]
b <- res.pca$ind$coord[,2]
c <- res.pca$ind$coord[,3]

data = data.frame(a,b,c)
scatter3D(b,c,a)
```

LINEAR REGRESSION on Happiness Score with the PCs:

Good layout to visualize correlation between set of variables:
```{r, echo = TRUE, fig.width=8, fig.height=8}
require(psych)
pairs.panels(temp_df,col="red")
```

Simple Linear Regression using only the 1st Principal Component:
```{r, echo = TRUE, fig.width=8, fig.height=8}

singlelr <- lm(full_best_df$Happiness_Score ~ res.pca$ind$coord[,1])
summary(singlelr)
plot(full_best_df$Happiness_Score,res.pca$ind$coord[,1])
abline(lm(res.pca$ind$coord[,1] ~full_best_df$Happiness_Score))
```

Multiple Linear Regression using 3 Principal Components:
```{r, echo = TRUE, fig.width=8, fig.height=8}
require(Hmisc);require(ggplot2);require(rgl)

predictors <- data.frame(res.pca$ind$coord[,1:3],happiness_score = full_best_df$Happiness_Score)
fit3pcs <- lm(happiness_score~ Dim.1 + Dim.2 + Dim.3, data=predictors)
summary(fit3pcs)

#Another way to do the same...
#pccc <- res.pca$ind$coord[,1:3] 
#threepcfit  <- lm(full_best_df$Happiness_Score ~ pccc)
#summary(threepcfit)
```

Contrast in Multiple Linear Regression using 1st, 2nd PCs against 1st, 3rd PCs:
```{r, echo = TRUE, fig.width=8, fig.height=8}

predictors <- data.frame(res.pca$ind$coord[,1:3],happiness_score = full_best_df$Happiness_Score)
fit2firstpcs <- lm(happiness_score~ Dim.1 + Dim.2, data=predictors)
summary(fit2firstpcs)


fitfirstthirdpcs <- lm(happiness_score~ Dim.1 + Dim.3, data=predictors)
summary(fitfirstthirdpcs)
```

As discovered, the 1st and 3rd pcs give much better results than the 1st combined with the 3rd pcs!:
```{r, echo = TRUE, fig.width=8, fig.height=8}
fitfirstthirdpcs <- lm(happiness_score~ Dim.1 + Dim.3, data=predictors)
summary(fitfirstthirdpcs)

plot(predictors$Dim.1,predictors$Dim.2)
abline(lm(res.pca$ind$coord[,1:2] ~full_best_df$Happiness_Score))

```
