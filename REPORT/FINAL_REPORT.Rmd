---
title: 'World Happiness: A Multivariate Analysis'
author: "Daniel Cooper, Maria Lechleitner, Dahmane Sheikh"
date: "May 2018"
output:
  html_document:
    df_print: paged
---

# Multivariate Normality Assessment: 

The first plot is the QQ plot on raw data, while the second one is when applying power transformation, which will be used for further analysis (factor analysis, pca, cluster analysis, predictions,...)

```{r, echo = TRUE, fig.width=8, fig.height=8}
require(dplyr)

#Using local path as cant' use the general path as this issue constantly appear: 
#cannot open file '../../DATA/full_best_df.csv': No such file or directoryError in file(file, "rt") : cannot open the connection

raw.df <- read.csv("C:\\Users\\mmlec\\Desktop\\2018_World_Happiness_Multivariate_Analysis\\DATA\\happiness.csv")

temp_df <- raw.df %>% select(-X,-Country,-Region)
rownames(temp_df) <- raw.df[1:132,2]

n <- nrow(temp_df); p <- ncol(temp_df)

mean <- colMeans(temp_df)
cov <- cov(temp_df)

# ordering mahalanobis distances
d_square <- mahalanobis(temp_df, mean,cov, tol=1e-20)
d_square <- sort(d_square)

# Generating a vector of quantiles
quantiles=(1:n-0.5)/n
x <- qchisq(quantiles,df=p)

# Plot

plot(x, d_square,
     pch=4, xlim=c(0,max(x)*1.2), ylim=c(0,max(d_square)*1.2),
     xlab="Chi-squared quantiles",
     ylab="Mahalanobis distances",
     main="Assessment of multivariate normality - QQ plot")
abline(a = 0, b = 1, col="blue")
text(x,d_square, labels=rownames(temp_df), pos=4,cex=0.7)

rm(cov,d_square,mean,n,p,quantiles,x, temp_df)
```


```{r, echo = TRUE, fig.width=8, fig.height=8}
normalized_df <- read.csv("C:/Users/A541U/Desktop/Semester 2/2. Descriptive R Project/2018_World_Happiness_Multivariate_Analysis/DATA/full_best_df.csv")

normalized_df <- normalized_df %>% select(-X,-Country,-Region)


#new df to use for further analysis
#full_best_df <- cbind(happiness[,2:3],best_df) 
#write.csv(full_best_df,file="full_best_df.csv")

rownames(normalized_df) <- raw.df[1:132,2]

n <- nrow(normalized_df); p <- ncol(normalized_df)
mean <- colMeans(normalized_df)
cov <- cov(normalized_df)

# ordering mahalanobis distances
d_square <- mahalanobis(normalized_df, mean,cov) # tol=1e-20) is used bc R is detecting singular 
d_square <- sort(d_square)

# Generating a vector of quantiles
quantiles=(1:n-0.5)/n
x <- qchisq(quantiles,df=p)

# Plot

plot(x, d_square,
     pch=4, xlim=c(0,max(x)*1.2), ylim=c(0,max(d_square)*1.2),
     xlab="Chi-squared quantiles",
     ylab="Mahalanobis distances",
     main="QQ plot on Normalized Data")
abline(a = 0, b = 1, col="blue")

text(x,d_square, labels=rownames(normalized_df), pos=4,cex=0.7)

rm(cov,d_square, mean,n,p,quantiles,x, raw.df, normalized_df)
```

# Principal Component Analysis:

Based on the correlation matrix, we can see that some variables have a weak to no correlation at all with the Happiness_Score and thus can be easily removed before PCA Analysis: (11 vars.)

Subseting the original dataset and calling the PCA function:
```{r, echo = TRUE, fig.width=8, fig.height=8}
require(dplyr);require(FactoMineR);require(factoextra)
require(ggcorrplot);require(ggplot2)

# full_best_df <- read.csv(file = "../../DATA/full_best_df.csv")
# this command yields this error: Error in file(file, "rt") : cannot open the connection

full_best_df <- read.csv("C:\\Users\\mmlec\\Desktop\\2018_World_Happiness_Multivariate_Analysis\\DATA\\full_best_df.csv")

#row.names(full_best_df) <- full_best_df$Country

temp_df <- full_best_df %>% select(
  -X,-Country,-Region,-Happiness_Score,-Generosity,-Total_Population,
  -Mental_and_Substance_Disorder_Index,-Alcohol_Consumption_Index,-Suicide_Index,
  -Population_Growth_Rate,-HIV_Disease_Index,-Compulsory_Education_in_Years,
  -Agricultural_Land_Percentage,-Forest_Area_Land_Percentage,-Legal_Rights_Index)

res.pca <- PCA(temp_df,graph=F)#PCA Function

#temp_df <- full_best_df %>% select(-X,-Country,-Region,-Happiness_Score,         -Total_Population,-Mental_and_Substance_Disorder_Index,-Compulsory_Education_in_Years, -Agricultural_Land_Percentage,-Generosity,-Forest_Area_Land_Percentage,         -Suicide_Index,-Legal_Rights_Index,-Infant_Immunization_Measles_Index, -HIV_Disease_Index, -Alcohol_Consumption_Index)
```

Scree plot + Correlation plot of the principal components:
```{r, echo = TRUE, fig.width=8, fig.height=8}
xaxis <- 1:10; eig <- data.frame(res.pca$eig); eig <- eig[1:10,]
temp_for_plot <- data.frame(eig,xaxis)

temp_for_plot$percentage.of.variance <- round(temp_for_plot$percentage.of.variance, digits=2)

ggplot(data=temp_for_plot, aes(x=factor(xaxis), y=percentage.of.variance)) +
  geom_bar(stat="identity", fill="steelblue") +
  geom_text(aes(label= paste0(temp_for_plot$percentage.of.variance, "%")), 
            fontface="bold", vjust=-0.3, size=4) +
  theme_minimal() + xlab("Principal Components") + ylab("Percentage of explained variances")+
  theme(axis.text = element_text(size=12), axis.title = element_text(size=14, face="bold"))+
  ggtitle("Scree Plot for PCA")+ theme(plot.title = element_text(hjust = 0.5)) 

#annotate(geom = "text", x = 1, y = 23,size=6, label = "Country Development", color = "black",angle = 90) +
#annotate(geom = "text", x = 2, y = 23, size=6, label = "<---- Freedom&Government trust", color = "black",angle = 90) +
#annotate(geom = "text", x = 3, y = 23,size=6, label = "<---- Air Pollution", color = "black",angle = 90)

temp <- res.pca$var$coord[,1:3]
temp <- temp[c(6,12,4,5,9,16,10,14,9,15,8,2,17,13,11,3,1,7),1:3]

ggcorrplot(temp, lab=T) + coord_flip() + ggtitle("Principal Components Scores")

#ggcorrplot(res.pca$var$coord[,1:3], lab=T, insig ="blank") + coord_flip() + ggtitle("Principal Components Scores")

#dimdesc(res.pca)

#ggcorrplot(res.pca$var$cos2, lab=T, insig ="blank") + coord_flip() + ggtitle("Quality of Representation per Dimension")

rm(eig,temp_for_plot,xaxis,temp_df,temp)
```

Biplot of PC1 and PC2 on the variables and countries, respectively:
```{r, echo = TRUE, fig.width=8, fig.height=8}
# Color by cos2 values: quality on the factor map

fviz_pca_var(res.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE) # Avoid text overlapping

temp_res_pca <- res.pca

row.names(temp_res_pca$ind$coord) <- full_best_df$Country

#still need to solve the layout error for this graph in this rmd. 
fviz_pca_ind(temp_res_pca, col.ind = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE) # Avoid text overlapping (slow if many points)
```

Demonstration that the 2pcs (their variables) do have a classification effect on the happiness_score:

```{r, echo = TRUE, fig.width=8, fig.height=8}
var <- get_pca_var(res.pca) #variables
ind <- get_pca_ind(res.pca) #individuals

target_Factorised <- full_best_df
target_Factorised$Happiness_Score <- cut(target_Factorised$Happiness_Score,breaks=5)

require(plyr)
target_Factorised$Happiness_Score <- revalue(target_Factorised$Happiness_Score, c("(-2.44,-1.46]"= "Less happy", "(-1.46,-0.486]" = "Not very happy", "(-0.486,0.486]" = "Mid happy", "(0.486,1.46]" = "Happy",  "(1.46,2.44]" = "Very happy"))

require(ggpubr)
ind.p <- fviz_pca_ind(res.pca,
             geom.ind = "text", # show points only (nbut not "text")
             col.ind = target_Factorised$Happiness_Score, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07", "blue","purple","red"),
             addEllipses = T, # Concentration ellipses
             ellipse.type= "euclid",
             ellipse.level= 1.35,
             repel=T)

ggpubr::ggpar(ind.p,
              title = "Principal Component Analysis - Grouping by happiness Score",
              subtitle = "Ellipse based on the euclidean distance from center",
              caption = "",
              xlab = "PC1", ylab = "PC2",
              legend.title = "Happiness Group", legend.position = "top")

```


# Linear Regression (Single and Multiple) based on PCA:

Simple Linear Regression using only the 1st Principal Component:
```{r, echo = TRUE, fig.width=8, fig.height=8}
require(lmtest)

pc1lm <- lm(full_best_df$Happiness_Score ~ res.pca$ind$coord[,1])
summary(pc1lm) #R_Square of 65% with just PC1
par(mfrow=c(2,2)) # init 4 charts in 1 panel
plot(pc1lm)
bptest(pc1lm)

temp_plot <- data.frame(pc1 = res.pca$ind$coord[,1], Happiness_Score = full_best_df$Happiness_Score)

ggplot(temp_plot, aes(x=pc1, y=Happiness_Score)) + geom_point() + geom_smooth(method="lm", col="red") +
  ggtitle(label="Simple Linear Regression",
  subtitle = labs(title =paste("Adj R2 =",signif(summary(pc1lm)$adj.r.squared, 5),
                               " Intercept =",signif(pc1lm$coef[[1]],5 ),
                               " Slope =",signif(pc1lm$coef[[2]], 5),
                               " P =",signif(summary(pc1lm)$coef[2,4], 5)))) +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust =0.5)) +
  xlab("1st Principal Component (Country Development)") + ylab("Happiness_Score") +
  theme(axis.text = element_text(size=12), axis.title = element_text(size=14, face="bold"))+
  theme(plot.title = element_text(hjust = 0.5))
```

Multiple Linear Regression with the first 3PCs:
```{r, echo = TRUE, fig.width=8, fig.height=8}
predictors3pcs <- data.frame(res.pca$ind$coord[,1:3],happiness_score = full_best_df$Happiness_Score)
fit3pcs <- lm(happiness_score~ Dim.1 + Dim.2, data=predictors3pcs)
summary(fit3pcs) #R_Square of 78%
plot(fit3pcs)
```

Regression Decision Tree:

```{r, echo = TRUE, fig.width=8, fig.height=8}

dt_temp <- full_best_df %>% select(-X,-Country,-Region)

library(rpart)
library(rpart.plot)

m1 <- rpart(Happiness_Score~., method="anova", data=dt_temp)
m1
rpart.plot(m1, type=3, digits=3, fallen.leaves=T)


dt_target_Factorised <- full_best_df
dt_target_Factorised$Happiness_Score <- cut(dt_target_Factorised$Happiness_Score,breaks=5)
require(plyr)
dt_target_Factorised$Happiness_Score <- revalue(dt_target_Factorised$Happiness_Score, c("(-2.44,-1.46]"= "Not Happy At All", "(-1.46,-0.486]" = "Not Really Happy", "(-0.486,0.486]" = "+/- Happy", "(0.486,1.46]" = "Happy",  "(1.46,2.44]" = "Really Happy"))

m2 <- rpart(Happiness_Score~., method="class", data=dt_target_Factorised)
rpart.plot(m2, type=3, digits=3, fallen.leaves=T)

```

# Feature selection:
Recursive Feature Elimination from caret package. It uses a random forest algo on each iteration to evaluate the model to explore all possible subsets of attributes. It comes out with a set of attributes that can be use to build an accurate model:

In this case, we have 5 interesting features with a R-square of 78%
```{r, echo = TRUE, fig.width=8, fig.height=8}
require(caret); require(mlbench); require(randomForest); require(dplyr)

selection_df <- full_best_df %>% select(-X,-Country,-Region)

control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results <- rfe(selection_df[,2:29], selection_df[,1], sizes=c(2:29), rfeControl=control)
print(results)
predictors(results)
plot(results,type=c("g","o"))

lmtest <- lm(Happiness_Score~ Econonmy_GDP_Per_Capita + Family + Freedom + 
               Internet_Usage_Index + Health_Life_Expectancy, data= selection_df)
summary(lmtest) #R_Square of 78% 
plot(lmtest)

importance <- varImp(results, scale=F)

require(MASS)
rlmtest <- rlm(Happiness_Score~ Econonmy_GDP_Per_Capita + Family + Freedom + 
               Internet_Usage_Index + Health_Life_Expectancy, data= selection_df)

summary(rlmtest)
plot(rlmtest)


```

# Cluster Analysis:

```{r, echo = TRUE, fig.width=8, fig.height=8}
require(dplyr)

full_best_df <- read.csv("C:/Users/A541U/Desktop/Semester 2/2. Descriptive R Project/2018_World_Happiness_Multivariate_Analysis/DATA/full_best_df.csv")

#row.names(full_best_df) <- full_best_df$Country

cluster_df <- full_best_df %>% select(
  -X,-Country,-Region,-Generosity,-Total_Population,
  -Mental_and_Substance_Disorder_Index,-Alcohol_Consumption_Index,-Suicide_Index,
  -Population_Growth_Rate,-HIV_Disease_Index,-Compulsory_Education_in_Years,
  -Agricultural_Land_Percentage,-Forest_Area_Land_Percentage,-Legal_Rights_Index)

k.means.fit <- kmeans(cluster_df, 5) # k = 5
#attributes(k.means.fit)

library(cluster)
clusplot(cluster_df, k.means.fit$cluster, main='2D representation of the Cluster solution',
         color=TRUE, shade=TRUE,
         labels=2, lines=0)

clusplot(cluster_df, target_Factorised$Happiness_Score, main='2D representation of the Cluster solution',
         color=TRUE, shade=TRUE,
         labels=2, lines=0)

library(fpc)
plotcluster(cluster_df, k.means.fit$cluster)

```
